{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Flatten, MaxPool2D, Input, Dropout, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Unzip the dataset\n",
    "# member = ('../GarbageClassification/garbage-classification.zip')\n",
    "# from zipfile import ZipFile\n",
    "# with ZipFile(member, 'r') as zipObj:\n",
    "#        # Extract all the contents of zip file in current directory\n",
    "#     zipObj.extractall()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "member = ('../GarbageClassification/Garbage classification/Garbage classification/')\n",
    "catagories = os.listdir(member)\n",
    "list_items = []\n",
    "for cat in catagories:\n",
    "    catagory_img = (member  + cat)\n",
    "    #catagory_img.glob('*.jpeg')\n",
    "    for _ in (glob.glob(catagory_img +'/'+'*.jpg')):\n",
    "        list_items.append([cat, _])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2527, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(list_items,columns = ['catagory', 'filepath'], index = None)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data.head(5)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "\n",
    "train_data = data[1:1600]\n",
    "val_data = data[1601:2000]\n",
    "test_data = data[2001:2527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Normalizing the images\n",
    "\n",
    "# #Resizing the images\n",
    "# def display_normal(a, title1 = 'Original'):\n",
    "#     plt.imshow(a), plt.title(title1)\n",
    "#     plt.show()\n",
    "    \n",
    "# def display(a,b, title1 = 'Original', title2 = 'Edited'):\n",
    "#     plt.subplot(121), plt.imshow(a), plt.title(title1)\n",
    "#     plt.subplot(122), plt.imshow(a), plt.title(title2)\n",
    "#     plt.show()\n",
    "    \n",
    "# #Preprocessing images\n",
    "# def preprocessing(data):\n",
    "#     #loading images\n",
    "#     #Getting 3 images to work with\n",
    "#     img = [cv2.imread(i, cv2.IMREAD_UNCHANGED) for i in data['filepath'].iloc[1:4]]\n",
    "#     print(type(img))\n",
    "#     print('Original Size: ', img[1].shape)\n",
    "    \n",
    "#     #--------------------------------------------\n",
    "    \n",
    "#     #Setting dim to resize\n",
    "#     height = 220\n",
    "#     width = 220\n",
    "    \n",
    "#     dim = (width, height)\n",
    "#     res_img =[]\n",
    "#     for i in range(len(img)):\n",
    "#         res = cv2.resize(img[i], dim, interpolation = cv2.INTER_LINEAR)\n",
    "#         res_img.append(res)\n",
    "        \n",
    "#     #Checking the resized image\n",
    "    \n",
    "#     print('Resized', res_img[1].shape)\n",
    "    \n",
    "#     #------------------------------------------------------------\n",
    "    \n",
    "#     #Removing noise from image - Gaussian blur\n",
    "    \n",
    "#     blurred_imgs =[]\n",
    "    \n",
    "#     for i in range(len(res_img)):\n",
    "#         blurred_img = cv2.GaussianBlur(res_img[i], (5,5),0)\n",
    "#         blurred_imgs.append(blurred_img)\n",
    "        \n",
    "#     #Segmentation \n",
    "#     #------------------------------------------------------------------\n",
    "#     image = blurred_imgs[0]\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#     ret,thresh = cv2.threshold(gray, 0,255,cv2.THRESH_BINARY+ cv2.THRESH_OTSU)\n",
    "    \n",
    "#     #More noise removal\n",
    "#     #------------------------------------------------------------------\n",
    "#     kernal = np.ones((3,3), np.uint8)\n",
    "#     opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernal, iterations=2)\n",
    "    \n",
    "#     #Sure background area\n",
    "#     sure_bg = cv2.dilate(opening, kernal, iterations = 3)\n",
    "    \n",
    "#     #Finding foreground area\n",
    "#     dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "#     ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "    \n",
    "#     # Finding unknown region\n",
    "#     sure_fg = np.uint8(sure_fg)\n",
    "#     unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    \n",
    "#     #Seperating different objects with different backgrounds\n",
    "#     #Markers labelling\n",
    "#     ret, markers  = cv2.connectedComponents(sure_fg)\n",
    "#     #Add one to all labels so that sure background is 0 not 1\n",
    "#     markers = markers+1\n",
    "    \n",
    "#     #Mark the unknown region with 0\n",
    "#     markers[unknown == 255] = 0\n",
    "    \n",
    "#     markers = cv2.watershed(image, markers)\n",
    "#     image[markers == -1] = [255,0,0]\n",
    "    \n",
    "#     #Displaying the markers on image\n",
    "#     display_normal(markers)\n",
    "    \n",
    "#     #Displaying segmented back ground\n",
    "#     display(thresh, sure_fg, 'Normal Thresh','Foreground area')\n",
    "#     #Visualizing one of the image in the array\n",
    "# #     original = image\n",
    "# #     edited = blurred_img[0]\n",
    "# #     display(image, thresh)\n",
    "# #     display_normal(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Preprocessing and duplication of images\n",
    "def preprocessing(img):\n",
    "    #Setting dim to resize\n",
    "    height = 220\n",
    "    width = 220\n",
    "    pps_imgs = []\n",
    "    dim = (width, height)\n",
    "    #res_img = cv2.resize(cv2.imread(img, cv2.IMREAD_UNCHANGED), dim, interpolation = cv2.INTER_LINEAR)\n",
    "    img = cv2.imread(str(img))\n",
    "    res_img = cv2.resize(img, (224,224))\n",
    "    if res_img.shape[2] ==1:\n",
    "        res_img = np.dstack([res_img, res_img, res_img])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255\n",
    "    res_img = cv2.cvtColor(res_img, cv2.COLOR_BGR2RGB)\n",
    "    pps_imgs.append(res_img)\n",
    "\n",
    "    #Removing noise from image - Gaussian blur\n",
    "\n",
    "    blurred_img = cv2.GaussianBlur(res_img, (5,5),0)\n",
    "    pps_imgs.append(blurred_img)\n",
    "    \n",
    "    #Segmentation \n",
    "    #------------------------------------------------------------------\n",
    "    gray = cv2.cvtColor(res_img, cv2.COLOR_RGB2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray, 0,255,cv2.THRESH_BINARY+ cv2.THRESH_OTSU)\n",
    "    \n",
    "    #More noise removal\n",
    "    #------------------------------------------------------------------\n",
    "    kernal = np.ones((3,3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernal, iterations=2)\n",
    "\n",
    "    #Sure background area\n",
    "    sure_bg = cv2.dilate(opening, kernal, iterations = 3)\n",
    "    \n",
    "    #Finding foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "    #pps_imgs.append(ret)\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    \n",
    "    #Seperating different objects with different backgrounds\n",
    "    #Markers labelling\n",
    "    ret, markers  = cv2.connectedComponents(sure_fg)\n",
    "    #Add one to all labels so that sure background is 0 not 1\n",
    "    markers = markers+1\n",
    "    #Mark the unknown region with 0\n",
    "    markers[unknown == 255] = 0\n",
    "    \n",
    "    markers = cv2.watershed(blurred_img, markers)\n",
    "    blurred_img[markers == -1] = [255,0,0]\n",
    "    pps_imgs.append(markers)\n",
    "    return pps_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calling the function\n",
    "\n",
    "imgs = preprocessing(data['filepath'].iloc[1])\n",
    "for i in imgs:\n",
    "    plt.imshow(i)\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working on the model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    input_size  = Input(shape = (255,255,3), name  =  'Input_Image')\n",
    "\n",
    "    #Layer 1 - Deapth Layer 1\n",
    "    x = Conv2D(64,(3,3), activation = 'relu', padding = 'same', name = 'ConvLayer1' )(input_size)\n",
    "    x = MaxPool2D((2,2), name = 'Maxpool1')(x)\n",
    "\n",
    "    #Layer 2 - Deapth layer 2\n",
    "    x = Conv2D(128,(3,3), activation = 'relu', padding = 'same', name = 'ConvLayer2')(x)\n",
    "    x = MaxPool2D((2,2), name = 'Maxpoo12')(x)\n",
    "    x = Dropout(0.7, name = 'Dropout1')(x)\n",
    "    #Layer 3 - Deapth layer 3\n",
    "    x = Conv2D(256,(3,3), activation= 'relu',padding = 'same',  name = 'ConvLayer3')(x)\n",
    "    x = MaxPool2D((2,2), name = 'Maxpool3')(x)\n",
    "\n",
    "    #Flatten the model\n",
    "\n",
    "    x = Flatten(name = 'Flatten')(x)\n",
    "\n",
    "    x = Dense(256, activation = 'relu' ,name = 'FC1')(x)\n",
    "\n",
    "    x = Dense(128, activation = 'relu', name = 'FC2')(x)\n",
    "    x = Dropout(0.5, name = 'Dropout2')(x)\n",
    "    x = Dense(6, activation = 'softmax', name = 'Fc3')(x)\n",
    "    \n",
    "    model = Model(input = input_size , output = x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0302 21:42:04.680824 11484 deprecation_wrapper.py:119] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0302 21:42:04.705449 11484 deprecation_wrapper.py:119] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0302 21:42:04.705449 11484 deprecation_wrapper.py:119] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0302 21:42:04.730353 11484 deprecation_wrapper.py:119] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0302 21:42:04.753133 11484 deprecation_wrapper.py:119] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0302 21:42:04.764650 11484 deprecation.py:506] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0302 21:42:04.764650 11484 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Image (InputLayer)     (None, 255, 255, 3)       0         \n",
      "_________________________________________________________________\n",
      "ConvLayer1 (Conv2D)          (None, 255, 255, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Maxpool1 (MaxPooling2D)      (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "ConvLayer2 (Conv2D)          (None, 127, 127, 128)     73856     \n",
      "_________________________________________________________________\n",
      "Maxpoo12 (MaxPooling2D)      (None, 63, 63, 128)       0         \n",
      "_________________________________________________________________\n",
      "Dropout1 (Dropout)           (None, 63, 63, 128)       0         \n",
      "_________________________________________________________________\n",
      "ConvLayer3 (Conv2D)          (None, 63, 63, 256)       295168    \n",
      "_________________________________________________________________\n",
      "Maxpool3 (MaxPooling2D)      (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               62980352  \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "Dropout2 (Dropout)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Fc3 (Dense)                  (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 63,384,838\n",
      "Trainable params: 63,384,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"In..., outputs=Tensor(\"Fc...)`\n"
     ]
    }
   ],
   "source": [
    "model = build_model() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0302 21:42:04.933470 11484 deprecation_wrapper.py:119] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0302 21:42:04.954326 11484 deprecation_wrapper.py:119] From c:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0302 21:42:04.961616 11484 deprecation.py:323] From c:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model\n",
    "\n",
    "opt = Adam(lr = 0.0001, decay = 1e-5)\n",
    "es = EarlyStopping(patience=5)\n",
    "chkpt = ModelCheckpoint(filepath= 'bestmodel',save_best_only=True, save_weights_only=True)\n",
    "model.compile(loss= 'binary_crossentropy', metrics= ['accuracy'], optimizer= opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
